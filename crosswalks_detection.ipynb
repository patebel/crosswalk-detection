{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"vrUhXR79JaXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657185662863,"user_tz":-120,"elapsed":21820,"user":{"displayName":"Visione Percezione","userId":"15109230762989705109"}},"outputId":"7c10db32-4040-46e9-d8a7-038b93291bd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Connecting to Drive....\n","/content/gdrive/MyDrive/project_VeP\n","Done!\n"]}],"source":["from google.colab import drive\n","\n","folder = 'project_VeP'#@param{type:\"string\"}\n","\n","drive.mount('/content/gdrive', force_remount=True)\n","print('Connecting to Drive....')\n","\n","%cd /content/gdrive/MyDrive/$folder/\n","print('Done!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qk0rYiBfJyu9"},"outputs":[],"source":["!git clone https://github.com/ultralytics/yolov5\n","!pip install -r yolov5/requirements.txt\n","import torch\n","print(\"Repo Clone Completed!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fX8oygCeJ58R"},"outputs":[],"source":["epoch = 300 #@param {type:\"slider\", min:100, max:1000, step:10}\n","training_option = 'Train new CNN' #@param [\"Train new CNN\", \"Resume an interrupted Training\"]\n","weight = 'yolov5m.pt' #@param[\"yolov5s.pt\",\"yolov5m.pt\",\"yolov5l.pt\",\"yolov5x.pt\"]\n","batch = 64 #@param {type:\"slider\", min:1, max:64, step:1}\n","\n","if training_option == 'Train new CNN':\n","  !python /content/gdrive/MyDrive/$folder/yolov5/train.py --img 512 --batch $batch --epochs $epoch --data /content/gdrive/MyDrive/$folder/training_dataset/data.yaml --weights $weight --cache --project /content/gdrive/MyDrive/$folder/training_results/\n","else:\n","  !python /content/gdrive/MyDrive/$folder/yolov5/train.py --resume /content/gdrive/MyDrive/$folder/training_results/export/weights/last.pt"]},{"cell_type":"markdown","metadata":{"id":"SdQx51l66Ewg"},"source":["#Metriche\n","Il codice seguente calcola le metriche su delle immagini di test. Vengono poi confrontati i grafici della curva per la F1, sia nel caso del training che sulle immagini di test."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRVg3I4i6Nb1"},"outputs":[],"source":["!python /content/gdrive/MyDrive/$folder/yolov5/val.py --data /content/gdrive/MyDrive/$folder/test_dataset/data.yaml --weights /content/gdrive/MyDrive/$folder/training_results/exp2/weights/best.pt --project /content/gdrive/MyDrive/$folder/test_results/ --img 512 --iou 0.65 --half"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwOOS_OXFo8z"},"outputs":[],"source":["#Printing result to confront\n","from PIL import Image\n","\n","precision_training = '/content/gdrive/MyDrive/'+folder+'/training_results/exp5/F1_curve.png'\n","precision_test = '/content/gdrive/MyDrive/'+folder+'/test_results/exp2/F1_curve.png'\n","\n","im1 = Image.open(precision_training)\n","im2 = Image.open(precision_test)\n","\n","print(\"F1 Training\")\n","display(im1)\n","print(\"F1 Test\")\n","display(im2)"]},{"cell_type":"markdown","metadata":{"id":"t02X8l0EsoEz"},"source":["#Detection\n","Effettuiamo la detection con YoloV5, definiamo la funzione che ci permette di fare il Merge delle bounding box estratte, e infine calcoliamo le inferenze con eventuali merge."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8WkYwwhcmOxH"},"outputs":[],"source":["!python /content/gdrive/MyDrive/$folder/yolov5/detect.py --source /content/gdrive/MyDrive/$folder/detection/exp --weights /content/gdrive/MyDrive/$folder/training_results/exp/weights/best.pt --project /content/gdrive/MyDrive/$folder/detection_results/ --imgsz 512 --save-txt --save-conf --exist-ok --nosave"]},{"cell_type":"code","source":["import glob\n","import os\n","import shutil\n","import numpy as np\n","import cv2 as cv\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot as plt\n","\n","#Bounding Box Merge Algorithm\n","def merge_bounding_boxes(bounding_boxes,image_width,image_height):\n","  [x,y] = [image_height,image_width]\n","  [w,h] = [0,0]\n","  for i in range(0,bounding_boxes.shape[0]):\n","    if(bounding_boxes.ndim == 1):\n","      center_x_1 = int(bounding_boxes[0]*image_width)\n","      center_y_1 = int(bounding_boxes[1]*image_height) \n","      width_1 = int(bounding_boxes[2]*image_width) \n","      height_1 = int(bounding_boxes[3]*image_height)\n","      x = int(center_x_1 - (width_1/2))\n","      y = int(center_y_1 - (height_1/2))\n","      w = int(center_x_1 + (width_1/2))\n","      h = int(center_y_1 + (height_1/2))\n","    else:\n","      center_x_1 = int(bounding_boxes[i,0]*image_width)\n","      center_y_1 = int(bounding_boxes[i,1]*image_height) \n","      width_1 = int(bounding_boxes[i,2]*image_width) \n","      height_1 = int(bounding_boxes[i,3]*image_height)\n","      vert_x = int(center_x_1 - (width_1/2))\n","      vert_y = int(center_y_1 - (height_1/2))\n","      vert_w = int(center_x_1 + (width_1/2))\n","      vert_h = int(center_y_1 + (height_1/2))\n","      if(vert_x < x):\n","        x = vert_x\n","      if(vert_y < y):\n","        y = vert_y\n","      if(vert_w > w):\n","        w = vert_w\n","      if(vert_h > h):\n","        h = vert_h\n","    return np.array([x,y,w,h])"],"metadata":{"id":"0fBYLiJye1G2","executionInfo":{"status":"ok","timestamp":1657186431918,"user_tz":-120,"elapsed":1081,"user":{"displayName":"Visione Percezione","userId":"15109230762989705109"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CBdtnJq8j3Sy"},"outputs":[],"source":["path = '/content/gdrive/MyDrive/'+folder+'/detection_results/exp/labels/'\n","img_path = '/content/gdrive/MyDrive/'+folder+'/detection/exp/'\n","save_path = '/content/gdrive/MyDrive/'+folder+'/detection_results/exp/'\n","\n","#shutil.copytree(img_path, save_path)\n","\n","for filename in glob.glob(os.path.join(path, '*.txt')):\n","  with open(os.path.join(os.getcwd(),filename), 'r') as f:\n","    bounding_boxes = None\n","    confidences = None\n","    image_name = os.path.basename(filename).replace('txt', 'jpg')\n","    for line in f:\n","      cl, label_x, label_y, label_w, label_h, conf = line.split(' ')\n","      b = float(conf)\n","      a = np.array([float(label_x),float(label_y),float(label_w),float(label_h)])\n","      bounding_boxes = (np.vstack((bounding_boxes, a)) if (bounding_boxes is not None) else a)\n","      confidences = (np.vstack((confidences, b)) if (confidences is not None) else b)\n","    #Image Elaboration\n","    image = cv.imread(img_path+image_name)\n","    [image_height, image_width, levels] = image.shape\n","    conf_max = np.amax(confidences)\n","    [x,y,w,h] = merge_bounding_boxes(bounding_boxes, image_width, image_height)\n","    #Create Rect\n","    cv.rectangle(image, (x,y), (w,h), (0,0,255), 4)\n","    cv.putText(image, 'crosswalk ' + \"%.2f\" % conf_max, (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n","    #Saving Image\n","    print('Saving ' + image_name)\n","    cv.imwrite(save_path+image_name, image)"]},{"cell_type":"markdown","source":["#Intersection Over Union (IoU)\n","A questo punto calcoliamo la metrica IoU con le nostre inferenze. Abbiamo definito noi una nostra funzione per effettuare il calcolo"],"metadata":{"id":"6w5Bt_PYgl5O"}},{"cell_type":"code","execution_count":31,"metadata":{"id":"B0nBcQRK3A62","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657189597524,"user_tz":-120,"elapsed":10349,"user":{"displayName":"Visione Percezione","userId":"15109230762989705109"}},"outputId":"6f61a24b-8182-4599-977e-d9fd95671180"},"outputs":[{"output_type":"stream","name":"stdout","text":["IoU: 0.77\n"]}],"source":["#INTERESCTION OVER UNION (IOU)\n","def compute_iou(box1, box2):\n","  #DATA: box1 = [L1, T1, R1, B1], box2 = [L2, T2, R2, B2]\n","  L_inter = max(box1[0], box2[0])\n","  T_inter = max(box1[1], box2[1])\n","  R_inter = min(box1[2], box2[2])\n","  B_inter = min(box1[3], box2[3])\n","  if(R_inter < L_inter) or (B_inter < T_inter):\n","    return 0\n","  A_inter = (R_inter - L_inter) * (B_inter - T_inter)\n","  A1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n","  A2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n","  A_union = A1 + A2 - A_inter\n","  iou = A_inter/A_union\n","  return iou\n","\n","#READING DATA AND CALCULATING IOU\n","dataset_path = '/content/gdrive/MyDrive/'+folder+'/intersection_over_union/dataset/'\n","detection_path = '/content/gdrive/MyDrive/'+folder+'/detection_results/exp/labels/'\n","images_path = '/content/gdrive/MyDrive/'+folder+'/detection/exp/'\n","\n","iou_array = None\n","\n","for filename_1 in glob.glob(os.path.join(dataset_path, '*.txt')):\n","  with open(os.path.join(os.getcwd(),filename_1), 'r') as f:\n","    name_1 = os.path.basename(filename_1)\n","    for filename_2 in glob.glob(os.path.join(detection_path, '*.txt')):\n","      name_2 = os.path.basename(filename_2)\n","      with open(os.path.join(os.getcwd(),filename_2), 'r') as g:\n","        if(name_1 == name_2):\n","          image_name = os.path.basename(filename_2).replace('txt', 'jpg')\n","          bounding_boxes_1 = None\n","          bounding_boxes_2 = None\n","          for line in f:\n","            cl_1, label_x_1, label_y_1, label_w_1, label_h_1 = line.split(' ')\n","            a_1 = np.array([float(label_x_1),float(label_y_1),float(label_w_1),float(label_h_1)])\n","            bounding_boxes_1 = (np.vstack((bounding_boxes_1, a_1)) if (bounding_boxes_1 is not None) else a_1)\n","          for line in g:\n","            cl_2, label_x_2, label_y_2, label_w_2, label_h_2, conf_2 = line.split(' ')\n","            a_2 = np.array([float(label_x_2),float(label_y_2),float(label_w_2),float(label_h_2)])\n","            bounding_boxes_2 = (np.vstack((bounding_boxes_2, a_2)) if (bounding_boxes_2 is not None) else a_2)\n","          image = cv.imread(images_path+image_name)\n","          [image_height, image_width, levels] = image.shape\n","          merge_box_1 = merge_bounding_boxes(bounding_boxes_1, image_width, image_height)\n","          merge_box_2 = merge_bounding_boxes(bounding_boxes_2, image_width, image_height)\n","          iou = compute_iou(merge_box_1, merge_box_2)\n","          iou_array = (np.vstack((iou_array, iou)) if (iou_array is not None) else iou)\n","        else:\n","          continue\n","print('IoU: ' + str(iou_array.mean())[:4])"]},{"cell_type":"code","source":[""],"metadata":{"id":"mXu5igcSly1s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Video Detection\n","Anche qui effettuiamo la detection con YoloV5, e andiamo a sostituire i frame con le detection di YoloV5 con i frame contenenti le nostre bounding box dopo il merge."],"metadata":{"id":"f9VAPlIug4S6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dyEI0za4vSd"},"outputs":[],"source":["#VIDEO DETECTION\n","video = 'video1.mp4' #@param {type:\"string\"}\n","!python /content/gdrive/MyDrive/$folder/yolov5/detect.py --source /content/gdrive/MyDrive/$folder/video/$video --weights /content/gdrive/MyDrive/$folder/training_results/exp/weights/best.pt --project /content/gdrive/MyDrive/$folder/video_results/ --imgsz 512 --save-txt --save-conf --exist-ok #--nosave"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":291,"status":"error","timestamp":1657188944307,"user":{"displayName":"Visione Percezione","userId":"15109230762989705109"},"user_tz":-120},"id":"h7-4bjqYarHN","outputId":"42abda89-f023-4824-ce2c-c62b4eebc845"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-0698e9a239b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/MyDrive/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/video_results/exp/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mframes_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/MyDrive/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/video_results/exp/frames/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mvideo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading Video: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'video' is not defined"]}],"source":["#CREATING INFERENCE ON VIDEO\n","import glob\n","import os\n","import shutil\n","import numpy as np\n","import cv2 as cv\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot as plt\n","\n","path = '/content/gdrive/MyDrive/'+folder+'/video_results/exp/labels/'\n","video_path = '/content/gdrive/MyDrive/'+folder+'/video/'\n","save_path = '/content/gdrive/MyDrive/'+folder+'/video_results/exp/'\n","frames_path = '/content/gdrive/MyDrive/'+folder+'/video_results/exp/frames/'\n","video_name = video.replace('.mp4', '')\n","\n","print('Reading Video: '+video_path+video)\n","v = cv.VideoCapture(video_path+video)\n","frame_count = int(v.get(cv.CAP_PROP_FRAME_COUNT))\n","fps = v.get(cv.CAP_PROP_FPS)\n","video_w = int(v.get(cv.CAP_PROP_FRAME_WIDTH))\n","video_h = int(v.get(cv.CAP_PROP_FRAME_HEIGHT))\n","print('Video Info' + '  FPS: '+str(fps)+' Width: '+str(video_w)+' Height: '+str(video_h))\n","\n","frames = None\n","for filename in glob.glob(os.path.join(path, '*.txt')):\n","  with open(os.path.join(os.getcwd(),filename), 'r') as f:\n","    bounding_boxes = None\n","    confidences = None\n","    #Saves the Frame number in an array\n","    frame_num = int(os.path.basename(filename).replace('.txt', '').replace(video_name +'_',''))\n","    frames = (np.vstack((frames, frame_num)) if (frames is not None) else frame_num)\n","    for line in f:\n","      cl, label_x, label_y, label_w, label_h, conf = line.split(' ')\n","      b = float(conf)\n","      a = np.array([float(label_x),float(label_y),float(label_w),float(label_h)])\n","      bounding_boxes = (np.vstack((bounding_boxes, a)) if (bounding_boxes is not None) else a)\n","      confidences = (np.vstack((confidences, b)) if (confidences is not None) else b)\n","    conf_max = np.amax(confidences)\n","    #Get Frames from Video\n","    v.set(cv.CAP_PROP_POS_FRAMES, frame_num)\n","    res, image = v.read()\n","    image_height = video_h\n","    image_width = video_w\n","    [x,y,w,h] = merge_bounding_boxes(bounding_boxes, image_width, image_height)\n","    cv.rectangle(image, (x,y), (w,h), (0,0,255), 4)\n","    cv.putText(image, 'crosswalk ' + \"%.2f\" % conf_max, (x, y+20), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n","    if image is None:\n","      continue\n","    cv.imwrite(frames_path+str(frame_num)+'.jpg', image)\n","v.release()\n","\n","#SAVING NEW VIDEO INFERENCES\n","cap = cv.VideoCapture(video_path+video)\n","vid_writer = cv.VideoWriter(save_path+video, cv.VideoWriter_fourcc(*'mp4v'), fps, (video_w, video_h))\n","frame_num = -1;\n","while (cap.isOpened()):\n","  frame_num +=1\n","  ret, frame = cap.read()\n","  if ret == True:\n","    if(frame_num in frames):\n","      frame = cv.imread('/content/gdrive/MyDrive/'+folder+'/video_results/exp/frames/'+str(frame_num)+'.jpg')\n","    vid_writer.write(frame)\n","  else:\n","    break\n","cap.release()\n","vid_writer.release()\n","print('Result Saved on '+save_path+video)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"crosswalks_detection.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}