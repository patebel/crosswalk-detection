{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vrUhXR79JaXF"},"outputs":[],"source":["from google.colab import drive\n","\n","folder = 'project_VeP'#@param{type:\"string\"}\n","\n","drive.mount('/content/gdrive')\n","print('Connecting to Drive....')\n","\n","%cd /content/gdrive/MyDrive/$folder/\n","print('Done!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qk0rYiBfJyu9"},"outputs":[],"source":["!git clone https://github.com/ultralytics/yolov5\n","!pip install -r yolov5/requirements.txt\n","import torch\n","print(\"Repo Clone Completed!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fX8oygCeJ58R"},"outputs":[],"source":["epoch = 300 #@param {type:\"slider\", min:100, max:1000, step:10}\n","training_option = 'Train new CNN' #@param [\"Train new CNN\", \"Resume an interrupted Training\"]\n","weight = 'yolov5m.pt' #@param[\"yolov5s.pt\",\"yolov5m.pt\",\"yolov5l.pt\",\"yolov5x.pt\"]\n","batch = 64 #@param {type:\"slider\", min:1, max:64, step:1}\n","\n","if training_option == 'Train new CNN':\n","  !python /content/gdrive/MyDrive/$folder/yolov5/train.py --img 512 --batch $batch --epochs $epoch --data /content/gdrive/MyDrive/$folder/training_dataset/data.yaml --weights $weight --cache --project /content/gdrive/MyDrive/$folder/training_results/\n","else:\n","  !python /content/gdrive/MyDrive/$folder/yolov5/train.py --resume /content/gdrive/MyDrive/$folder/training_results/export/weights/last.pt"]},{"cell_type":"markdown","source":["#Metriche\n","Il codice seguente calcola le metriche su delle immagini di test. Vengono poi confrontati i grafici della curva per la F1, sia nel caso del training che sulle immagini di test."],"metadata":{"id":"SdQx51l66Ewg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRVg3I4i6Nb1"},"outputs":[],"source":["!python /content/gdrive/MyDrive/$folder/yolov5/val.py --data /content/gdrive/MyDrive/$folder/test_dataset/data.yaml --weights /content/gdrive/MyDrive/$folder/training_results/exp5/weights/best.pt --project /content/gdrive/MyDrive/$folder/test_results/ --imgsz=512"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwOOS_OXFo8z"},"outputs":[],"source":["#Printing result to confront\n","from PIL import Image\n","\n","precision_training = '/content/gdrive/MyDrive/'+folder+'/training_results/exp5/F1_curve.png'\n","precision_test = '/content/gdrive/MyDrive/'+folder+'/test_results/exp2/F1_curve.png'\n","\n","im1 = Image.open(precision_training)\n","im2 = Image.open(precision_test)\n","\n","print(\"F1 Training\")\n","display(im1)\n","print(\"F1 Test\")\n","display(im2)"]},{"cell_type":"markdown","source":["#Detection\n","Salviamo le soltanto le label alla fine della detection, in questo modo disegniamo noi le bounding box."],"metadata":{"id":"t02X8l0EsoEz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8WkYwwhcmOxH"},"outputs":[],"source":["!python /content/gdrive/MyDrive/$folder/yolov5/detect.py --source /content/gdrive/MyDrive/$folder/detection/exp --weights /content/gdrive/MyDrive/$folder/training_results/exp2/weights/best.pt --project /content/gdrive/MyDrive/$folder/detection_results/ --imgsz 512 --save-txt --save-conf --exist-ok --nosave"]},{"cell_type":"code","source":["import glob\n","import os\n","import shutil\n","import numpy as np\n","import cv2 as cv\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot as plt\n","\n","path = '/content/gdrive/MyDrive/'+folder+'/detection_results/exp/labels/'\n","img_path = '/content/gdrive/MyDrive/'+folder+'/detection/exp/'\n","save_path = '/content/gdrive/MyDrive/'+folder+'/detection_results/exp/'\n","\n","#shutil.copytree(img_path, save_path)\n","\n","for filename in glob.glob(os.path.join(path, '*.txt')):\n","  with open(os.path.join(os.getcwd(),filename), 'r') as f:\n","    bounding_boxes = None\n","    confidences = None\n","    image_name = os.path.basename(filename).replace('txt', 'jpg')\n","    for line in f:\n","      cl, label_x, label_y, label_w, label_h, conf = line.split(' ')\n","      b = float(conf)\n","      a = np.array([float(label_x),float(label_y),float(label_w),float(label_h)])\n","      bounding_boxes = (np.vstack((bounding_boxes, a)) if (bounding_boxes is not None) else a)\n","      confidences = (np.vstack((confidences, b)) if (confidences is not None) else b)\n","\n","    #Image Elaboration\n","    image = cv.imread(img_path+image_name)\n","    [image_height, image_width, levels] = image.shape\n","    \n","    conf_max = np.amax(confidences)\n","\n","    [x,y] = [image_height,image_width]\n","    [w,h] = [0,0]\n","    for i in range(0,bounding_boxes.shape[0]):\n","      if(bounding_boxes.ndim == 1):\n","        center_x_1 = int(bounding_boxes[0]*image_width)\n","        center_y_1 = int(bounding_boxes[1]*image_height) \n","        width_1 = int(bounding_boxes[2]*image_width) \n","        height_1 = int(bounding_boxes[3]*image_height)\n","        x = int(center_x_1 - (width_1/2))\n","        y = int(center_y_1 - (height_1/2))\n","        w = int(center_x_1 + (width_1/2))\n","        h = int(center_y_1 + (height_1/2))\n","      else:\n","        center_x_1 = int(bounding_boxes[i,0]*image_width)\n","        center_y_1 = int(bounding_boxes[i,1]*image_height) \n","        width_1 = int(bounding_boxes[i,2]*image_width) \n","        height_1 = int(bounding_boxes[i,3]*image_height)\n","        vert_x = int(center_x_1 - (width_1/2))\n","        vert_y = int(center_y_1 - (height_1/2))\n","        vert_w = int(center_x_1 + (width_1/2))\n","        vert_h = int(center_y_1 + (height_1/2))\n","        if(vert_x < x):\n","          x = vert_x\n","        if(vert_y < y):\n","          y = vert_y\n","        if(vert_w > w):\n","          w = vert_w\n","        if(vert_h > h):\n","          h = vert_h\n","    \n","    #Create Rect\n","    cv.rectangle(image, (x,y), (w,h), (0,0,255), 4)\n","    cv.putText(image, 'crosswalk ' + \"%.2f\" % conf_max, (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n","    \n","    #Saving Image\n","    print('Saving ' + image_name)\n","    cv.imwrite(save_path+image_name, image)"],"metadata":{"id":"CBdtnJq8j3Sy"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"crosswalks_detection.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}